{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "honest-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "induced-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = \"C:/Users/yang/Desktop/nongzuowu/small/\"\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir,'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    \n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i*batch_size:(i+1)*batch_size] = features_batch\n",
    "        labels[i*batch_size:(i+1)*batch_size] = labels_batch\n",
    "        i+=1\n",
    "        if i * batch_size>=sample_count:\n",
    "            break\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "complex-monaco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2540 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = extract_features(train_dir, 2540)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "suffering-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (2540, 4*4*512))\n",
    "validation_features = np.reshape(validation_features, (1000, 4*4*512))\n",
    "test_features = np.reshape(test_features, (1000, 4*4*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liberal-width",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/yang/Desktop/nongzuowu/small/test'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "guilty-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(256, kernel_regularizer=regularizers.l2(0.001),\n",
    "                                  activation='relu'))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "respiratory-humanitarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,878,145\n",
      "Trainable params: 16,878,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-copper",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2540 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From <ipython-input-10-205f21f38de6>:47: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/100\n",
      "127/127 [==============================] - 62s 484ms/step - loss: 0.8032 - acc: 0.7366 - val_loss: 0.6850 - val_acc: 0.8150\n",
      "Epoch 2/100\n",
      "127/127 [==============================] - 61s 483ms/step - loss: 0.6574 - acc: 0.8154 - val_loss: 0.6197 - val_acc: 0.8520\n",
      "Epoch 3/100\n",
      "127/127 [==============================] - 62s 487ms/step - loss: 0.6099 - acc: 0.8441 - val_loss: 0.6335 - val_acc: 0.8270\n",
      "Epoch 4/100\n",
      "127/127 [==============================] - 62s 492ms/step - loss: 0.5622 - acc: 0.8650 - val_loss: 0.6061 - val_acc: 0.8510\n",
      "Epoch 5/100\n",
      "127/127 [==============================] - 62s 491ms/step - loss: 0.5390 - acc: 0.8740 - val_loss: 0.6069 - val_acc: 0.8480\n",
      "Epoch 6/100\n",
      "127/127 [==============================] - 63s 494ms/step - loss: 0.5084 - acc: 0.8835 - val_loss: 0.5412 - val_acc: 0.8800\n",
      "Epoch 7/100\n",
      "127/127 [==============================] - 63s 494ms/step - loss: 0.4954 - acc: 0.8894 - val_loss: 0.5391 - val_acc: 0.8780\n",
      "Epoch 8/100\n",
      "127/127 [==============================] - 63s 496ms/step - loss: 0.4798 - acc: 0.8972 - val_loss: 0.5188 - val_acc: 0.8850\n",
      "Epoch 9/100\n",
      "127/127 [==============================] - 63s 496ms/step - loss: 0.4696 - acc: 0.8969 - val_loss: 0.5091 - val_acc: 0.8880\n",
      "Epoch 10/100\n",
      "127/127 [==============================] - 63s 497ms/step - loss: 0.4458 - acc: 0.9130 - val_loss: 0.5067 - val_acc: 0.8910\n",
      "Epoch 11/100\n",
      "127/127 [==============================] - 63s 498ms/step - loss: 0.4341 - acc: 0.9161 - val_loss: 0.5007 - val_acc: 0.8970\n",
      "Epoch 12/100\n",
      "127/127 [==============================] - 63s 499ms/step - loss: 0.4274 - acc: 0.9138 - val_loss: 0.5142 - val_acc: 0.8800\n",
      "Epoch 13/100\n",
      "127/127 [==============================] - 63s 499ms/step - loss: 0.4238 - acc: 0.9165 - val_loss: 0.4791 - val_acc: 0.8940\n",
      "Epoch 14/100\n",
      "127/127 [==============================] - 63s 500ms/step - loss: 0.4062 - acc: 0.9217 - val_loss: 0.4776 - val_acc: 0.9030\n",
      "Epoch 15/100\n",
      "127/127 [==============================] - 63s 499ms/step - loss: 0.3953 - acc: 0.9236 - val_loss: 0.6259 - val_acc: 0.8590\n",
      "Epoch 16/100\n",
      "127/127 [==============================] - 63s 500ms/step - loss: 0.3851 - acc: 0.9268 - val_loss: 0.4644 - val_acc: 0.8910\n",
      "Epoch 17/100\n",
      "127/127 [==============================] - 64s 501ms/step - loss: 0.3757 - acc: 0.9315 - val_loss: 0.4793 - val_acc: 0.9000\n",
      "Epoch 18/100\n",
      "127/127 [==============================] - 64s 501ms/step - loss: 0.3634 - acc: 0.9378 - val_loss: 0.4612 - val_acc: 0.8930\n",
      "Epoch 19/100\n",
      "127/127 [==============================] - 64s 501ms/step - loss: 0.3559 - acc: 0.9398 - val_loss: 0.4584 - val_acc: 0.9020\n",
      "Epoch 20/100\n",
      "127/127 [==============================] - 64s 502ms/step - loss: 0.3523 - acc: 0.9382 - val_loss: 0.4614 - val_acc: 0.8970\n",
      "Epoch 21/100\n",
      "127/127 [==============================] - 64s 501ms/step - loss: 0.3288 - acc: 0.9465 - val_loss: 0.4981 - val_acc: 0.8960\n",
      "Epoch 22/100\n",
      "127/127 [==============================] - 64s 501ms/step - loss: 0.3279 - acc: 0.9449 - val_loss: 0.5005 - val_acc: 0.8930\n",
      "Epoch 23/100\n",
      "127/127 [==============================] - 64s 502ms/step - loss: 0.3192 - acc: 0.9492 - val_loss: 0.4679 - val_acc: 0.8950\n",
      "Epoch 24/100\n",
      "127/127 [==============================] - 64s 503ms/step - loss: 0.3014 - acc: 0.9531 - val_loss: 0.4718 - val_acc: 0.8920\n",
      "Epoch 25/100\n",
      "127/127 [==============================] - 64s 501ms/step - loss: 0.3055 - acc: 0.9531 - val_loss: 0.4587 - val_acc: 0.8980\n",
      "Epoch 26/100\n",
      "127/127 [==============================] - 64s 504ms/step - loss: 0.2886 - acc: 0.9579 - val_loss: 0.6334 - val_acc: 0.8650\n",
      "Epoch 27/100\n",
      "127/127 [==============================] - 64s 502ms/step - loss: 0.2889 - acc: 0.9559 - val_loss: 0.4855 - val_acc: 0.8950\n",
      "Epoch 28/100\n",
      "127/127 [==============================] - 64s 501ms/step - loss: 0.2965 - acc: 0.9504 - val_loss: 0.4681 - val_acc: 0.8990\n",
      "Epoch 29/100\n",
      "127/127 [==============================] - 64s 502ms/step - loss: 0.2715 - acc: 0.9610 - val_loss: 0.4830 - val_acc: 0.9000\n",
      "Epoch 30/100\n",
      "127/127 [==============================] - 64s 501ms/step - loss: 0.2732 - acc: 0.9634 - val_loss: 0.4810 - val_acc: 0.8930\n",
      "Epoch 31/100\n",
      "127/127 [==============================] - 64s 504ms/step - loss: 0.2734 - acc: 0.9610 - val_loss: 0.4715 - val_acc: 0.8990\n",
      "Epoch 32/100\n",
      "127/127 [==============================] - 64s 505ms/step - loss: 0.2655 - acc: 0.9618 - val_loss: 0.4706 - val_acc: 0.9080\n",
      "Epoch 33/100\n",
      "127/127 [==============================] - 64s 504ms/step - loss: 0.2508 - acc: 0.9661 - val_loss: 0.5137 - val_acc: 0.8990\n",
      "Epoch 34/100\n",
      "127/127 [==============================] - 64s 506ms/step - loss: 0.2509 - acc: 0.9677 - val_loss: 0.4794 - val_acc: 0.9030\n",
      "Epoch 35/100\n",
      "127/127 [==============================] - 64s 505ms/step - loss: 0.2479 - acc: 0.9685 - val_loss: 0.4745 - val_acc: 0.9070\n",
      "Epoch 36/100\n",
      "127/127 [==============================] - 64s 507ms/step - loss: 0.2475 - acc: 0.9669 - val_loss: 0.4775 - val_acc: 0.9010\n",
      "Epoch 37/100\n",
      "127/127 [==============================] - 64s 506ms/step - loss: 0.2376 - acc: 0.9665 - val_loss: 0.4920 - val_acc: 0.9030\n",
      "Epoch 38/100\n",
      "127/127 [==============================] - 64s 506ms/step - loss: 0.2353 - acc: 0.9728 - val_loss: 0.5895 - val_acc: 0.8920\n",
      "Epoch 39/100\n",
      "127/127 [==============================] - 64s 507ms/step - loss: 0.2281 - acc: 0.9732 - val_loss: 0.5292 - val_acc: 0.9060\n",
      "Epoch 40/100\n",
      "127/127 [==============================] - 64s 506ms/step - loss: 0.2257 - acc: 0.9732 - val_loss: 0.5230 - val_acc: 0.8950\n",
      "Epoch 41/100\n",
      "127/127 [==============================] - 64s 507ms/step - loss: 0.2226 - acc: 0.9748 - val_loss: 0.5156 - val_acc: 0.9020\n",
      "Epoch 42/100\n",
      "127/127 [==============================] - 64s 507ms/step - loss: 0.2183 - acc: 0.9736 - val_loss: 0.5056 - val_acc: 0.9030\n",
      "Epoch 43/100\n",
      "127/127 [==============================] - 64s 506ms/step - loss: 0.2160 - acc: 0.9744 - val_loss: 0.4589 - val_acc: 0.9080\n",
      "Epoch 44/100\n",
      "127/127 [==============================] - 64s 508ms/step - loss: 0.2124 - acc: 0.9764 - val_loss: 0.5002 - val_acc: 0.9010\n",
      "Epoch 45/100\n",
      "127/127 [==============================] - 65s 509ms/step - loss: 0.2008 - acc: 0.9819 - val_loss: 0.5456 - val_acc: 0.8940\n",
      "Epoch 46/100\n",
      "127/127 [==============================] - 64s 507ms/step - loss: 0.2075 - acc: 0.9783 - val_loss: 0.5061 - val_acc: 0.8980\n",
      "Epoch 47/100\n",
      "127/127 [==============================] - 64s 508ms/step - loss: 0.2018 - acc: 0.9803 - val_loss: 0.4992 - val_acc: 0.9090\n",
      "Epoch 48/100\n",
      "127/127 [==============================] - 64s 506ms/step - loss: 0.2001 - acc: 0.9799 - val_loss: 0.5285 - val_acc: 0.9010\n",
      "Epoch 49/100\n",
      "127/127 [==============================] - 64s 507ms/step - loss: 0.1983 - acc: 0.9807 - val_loss: 0.5016 - val_acc: 0.9010\n",
      "Epoch 50/100\n",
      "127/127 [==============================] - 64s 507ms/step - loss: 0.1870 - acc: 0.9854 - val_loss: 0.5738 - val_acc: 0.8950\n",
      "Epoch 51/100\n",
      "127/127 [==============================] - 64s 508ms/step - loss: 0.1933 - acc: 0.9811 - val_loss: 0.5193 - val_acc: 0.9050\n",
      "Epoch 52/100\n",
      "127/127 [==============================] - 64s 505ms/step - loss: 0.1843 - acc: 0.9819 - val_loss: 0.5324 - val_acc: 0.9010\n",
      "Epoch 53/100\n",
      "127/127 [==============================] - 64s 507ms/step - loss: 0.1828 - acc: 0.9858 - val_loss: 0.5558 - val_acc: 0.9030\n",
      "Epoch 54/100\n",
      "127/127 [==============================] - 64s 507ms/step - loss: 0.1799 - acc: 0.9843 - val_loss: 0.4974 - val_acc: 0.9120\n",
      "Epoch 55/100\n",
      "127/127 [==============================] - 65s 508ms/step - loss: 0.1738 - acc: 0.9862 - val_loss: 0.5719 - val_acc: 0.8990\n",
      "Epoch 56/100\n",
      "127/127 [==============================] - 65s 509ms/step - loss: 0.1704 - acc: 0.9878 - val_loss: 0.5232 - val_acc: 0.9120\n",
      "Epoch 57/100\n",
      "127/127 [==============================] - 65s 508ms/step - loss: 0.1743 - acc: 0.9843 - val_loss: 0.5573 - val_acc: 0.9070\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 65s 509ms/step - loss: 0.1684 - acc: 0.9878 - val_loss: 0.5556 - val_acc: 0.9080\n",
      "Epoch 59/100\n",
      "127/127 [==============================] - 65s 508ms/step - loss: 0.1714 - acc: 0.9882 - val_loss: 0.6131 - val_acc: 0.9060\n",
      "Epoch 60/100\n",
      "127/127 [==============================] - 65s 510ms/step - loss: 0.1653 - acc: 0.9878 - val_loss: 0.7603 - val_acc: 0.8850\n",
      "Epoch 61/100\n",
      "127/127 [==============================] - 64s 508ms/step - loss: 0.1627 - acc: 0.9870 - val_loss: 0.5786 - val_acc: 0.9030\n",
      "Epoch 62/100\n",
      "127/127 [==============================] - 65s 511ms/step - loss: 0.1662 - acc: 0.9866 - val_loss: 0.5863 - val_acc: 0.9030\n",
      "Epoch 63/100\n",
      "127/127 [==============================] - 65s 508ms/step - loss: 0.1547 - acc: 0.9909 - val_loss: 0.5630 - val_acc: 0.9110\n",
      "Epoch 64/100\n",
      "127/127 [==============================] - 65s 511ms/step - loss: 0.1654 - acc: 0.9858 - val_loss: 0.5599 - val_acc: 0.9100\n",
      "Epoch 65/100\n",
      "127/127 [==============================] - 65s 509ms/step - loss: 0.1664 - acc: 0.9850 - val_loss: 0.5830 - val_acc: 0.9020\n",
      "Epoch 66/100\n",
      "127/127 [==============================] - 65s 510ms/step - loss: 0.1580 - acc: 0.9898 - val_loss: 0.5270 - val_acc: 0.9100\n",
      "Epoch 67/100\n",
      "127/127 [==============================] - 65s 509ms/step - loss: 0.1476 - acc: 0.9937 - val_loss: 0.6074 - val_acc: 0.9030\n",
      "Epoch 68/100\n",
      "127/127 [==============================] - 64s 507ms/step - loss: 0.1639 - acc: 0.9843 - val_loss: 0.5159 - val_acc: 0.9100\n",
      "Epoch 69/100\n",
      "127/127 [==============================] - 64s 507ms/step - loss: 0.1576 - acc: 0.9898 - val_loss: 0.5837 - val_acc: 0.9090\n",
      "Epoch 70/100\n",
      "127/127 [==============================] - 64s 506ms/step - loss: 0.1461 - acc: 0.9917 - val_loss: 0.5963 - val_acc: 0.9080\n",
      "Epoch 71/100\n",
      "127/127 [==============================] - 64s 506ms/step - loss: 0.1500 - acc: 0.9913 - val_loss: 0.6235 - val_acc: 0.8980\n",
      "Epoch 72/100\n",
      "127/127 [==============================] - 65s 508ms/step - loss: 0.1464 - acc: 0.9909 - val_loss: 0.6705 - val_acc: 0.8960\n",
      "Epoch 73/100\n",
      "127/127 [==============================] - 65s 508ms/step - loss: 0.1444 - acc: 0.9902 - val_loss: 0.6690 - val_acc: 0.9040\n",
      "Epoch 74/100\n",
      "127/127 [==============================] - 64s 508ms/step - loss: 0.1370 - acc: 0.9937 - val_loss: 0.6470 - val_acc: 0.9000\n",
      "Epoch 75/100\n",
      "127/127 [==============================] - 64s 507ms/step - loss: 0.1475 - acc: 0.9882 - val_loss: 0.6522 - val_acc: 0.9050\n",
      "Epoch 76/100\n",
      "127/127 [==============================] - 64s 505ms/step - loss: 0.1385 - acc: 0.9941 - val_loss: 0.9665 - val_acc: 0.8710\n",
      "Epoch 77/100\n",
      "127/127 [==============================] - 64s 506ms/step - loss: 0.1359 - acc: 0.9937 - val_loss: 1.0713 - val_acc: 0.8620\n",
      "Epoch 78/100\n",
      "127/127 [==============================] - 64s 506ms/step - loss: 0.1426 - acc: 0.9898 - val_loss: 0.6044 - val_acc: 0.9070\n",
      "Epoch 79/100\n",
      "127/127 [==============================] - 64s 506ms/step - loss: 0.1282 - acc: 0.9961 - val_loss: 0.6764 - val_acc: 0.9100\n",
      "Epoch 80/100\n",
      "127/127 [==============================] - 64s 506ms/step - loss: 0.1397 - acc: 0.9913 - val_loss: 0.6021 - val_acc: 0.9100\n",
      "Epoch 81/100\n",
      "127/127 [==============================] - 64s 507ms/step - loss: 0.1350 - acc: 0.9929 - val_loss: 0.6614 - val_acc: 0.9030\n",
      "Epoch 82/100\n",
      "127/127 [==============================] - 64s 506ms/step - loss: 0.1320 - acc: 0.9965 - val_loss: 0.6811 - val_acc: 0.9060\n",
      "Epoch 83/100\n",
      "127/127 [==============================] - 64s 507ms/step - loss: 0.1405 - acc: 0.9909 - val_loss: 0.6707 - val_acc: 0.9100\n",
      "Epoch 84/100\n",
      "127/127 [==============================] - 64s 506ms/step - loss: 0.1338 - acc: 0.9921 - val_loss: 0.6315 - val_acc: 0.9120\n",
      "Epoch 85/100\n",
      "127/127 [==============================] - 64s 507ms/step - loss: 0.1311 - acc: 0.9937 - val_loss: 0.6291 - val_acc: 0.9120\n",
      "Epoch 86/100\n",
      "127/127 [==============================] - 65s 509ms/step - loss: 0.1284 - acc: 0.9929 - val_loss: 0.6148 - val_acc: 0.9100\n",
      "Epoch 87/100\n",
      "127/127 [==============================] - 64s 505ms/step - loss: 0.1302 - acc: 0.9921 - val_loss: 0.7496 - val_acc: 0.9100\n",
      "Epoch 88/100\n",
      "127/127 [==============================] - 64s 507ms/step - loss: 0.1276 - acc: 0.9933 - val_loss: 0.6981 - val_acc: 0.9070\n",
      "Epoch 89/100\n",
      "127/127 [==============================] - 65s 509ms/step - loss: 0.1359 - acc: 0.9917 - val_loss: 0.6657 - val_acc: 0.9100\n",
      "Epoch 90/100\n",
      "127/127 [==============================] - 64s 506ms/step - loss: 0.1276 - acc: 0.9937 - val_loss: 0.6423 - val_acc: 0.9190\n",
      "Epoch 91/100\n",
      "127/127 [==============================] - 64s 505ms/step - loss: 0.1268 - acc: 0.9933 - val_loss: 0.6828 - val_acc: 0.9050\n",
      "Epoch 92/100\n",
      "127/127 [==============================] - 64s 507ms/step - loss: 0.1272 - acc: 0.9929 - val_loss: 0.7032 - val_acc: 0.9040\n",
      "Epoch 93/100\n",
      "127/127 [==============================] - 64s 507ms/step - loss: 0.1226 - acc: 0.9937 - val_loss: 0.6283 - val_acc: 0.9190\n",
      "Epoch 94/100\n",
      "127/127 [==============================] - 64s 505ms/step - loss: 0.1192 - acc: 0.9953 - val_loss: 0.7810 - val_acc: 0.9000\n",
      "Epoch 95/100\n",
      "127/127 [==============================] - 64s 505ms/step - loss: 0.1206 - acc: 0.9933 - val_loss: 0.6979 - val_acc: 0.9040\n",
      "Epoch 96/100\n",
      "127/127 [==============================] - 64s 505ms/step - loss: 0.1215 - acc: 0.9929 - val_loss: 0.6269 - val_acc: 0.9170\n",
      "Epoch 97/100\n",
      "127/127 [==============================] - 64s 505ms/step - loss: 0.1197 - acc: 0.9941 - val_loss: 0.6649 - val_acc: 0.9020\n",
      "Epoch 98/100\n",
      "127/127 [==============================] - 64s 506ms/step - loss: 0.1150 - acc: 0.9957 - val_loss: 0.7021 - val_acc: 0.9060\n",
      "Epoch 99/100\n",
      "127/127 [==============================] - 65s 508ms/step - loss: 0.1245 - acc: 0.9925 - val_loss: 0.6402 - val_acc: 0.9070\n",
      "Epoch 100/100\n",
      " 43/127 [=========>....................] - ETA: 31s - loss: 0.1131 - acc: 0.9942"
     ]
    }
   ],
   "source": [
    "conv_base.trainable=True\n",
    "\n",
    "\n",
    "set_trainable=False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name=='block5_conv1':\n",
    "        set_trainable=True\n",
    "    if set_trainable:\n",
    "        layer.trainable=True\n",
    "    else:\n",
    "        layer.trainable=False\n",
    "        \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "               rescale=1./255,\n",
    "               rotation_range=40,\n",
    "               width_shift_range=0.2,\n",
    "               height_shift_range=0.2,\n",
    "               shear_range=0.2,\n",
    "               horizontal_flip=0.2,\n",
    "               fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=(150,150),\n",
    "            batch_size=20,\n",
    "            class_mode='binary')\n",
    "\n",
    "validation_genetator = test_datagen.flow_from_directory(\n",
    "            validation_dir,\n",
    "            target_size=(150,150),\n",
    "            batch_size = 20,\n",
    "            class_mode = 'binary')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(train_generator, \n",
    "                              steps_per_epoch=127, \n",
    "                              epochs=100,\n",
    "                              validation_data=validation_genetator,\n",
    "                              validation_steps=50,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"hulianwang+(sample=2540&l2=0.001).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator=test_datagen.flow_from_directory(\n",
    "                test_dir,\n",
    "                target_size=(150, 150),\n",
    "                batch_size=20,\n",
    "                class_mode='binary')\n",
    "\n",
    "\n",
    "test_loss, test_acc=model.evaluate_generator(test_generator, steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}